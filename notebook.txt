########################
Code design:

Our code is contained in `main.py` and our unit tests are stored in `unit_tests.py`. We also use the `experiments.sh` script for running our experiments.
Inside our `main.py` file, we have:
    - running_threads: a list of threads that are currently running
    - running_sockets: a list of sockets that are currently running
    - run_event: an event that is used to signal when to stop running
These three variables are used to keep track of the threads and sockets that are currently running, and to signal when to stop running. This in turn
helps with the graceful shutdown of the program.

In `get_sys_args`, we define what flags we want to use for our program. You can read more about each specific flag in the documentation for the function.
`get_sys_args` parses the flag values and returns it to the program for use.

In our `main` function, we first create a `shutdown_thread` that shutsdown the sockets, servers, and threads, after a specified `duration`. We call `gracefully_shutdown`
to gracefully shutdown these threads after the duration. Then after starting the `shutdown_thread` we start three threads in `start_threads`. Each thread has its own idenitier
 and is responsible for running a machine. Each thread calls `thread_process` to start running the thread. In `thread_process`, we
 0) Initialize an empty network queue for the specific machine
 1) Get a list of system arguments that are relevant to the machine
 2) Initialize a log file for the process with `init_log_file`
 3) Create a socket for the machine running on localhost with port = 3000 + identifier
 4) Start a thread that listens to connections with the function `listen_for_connections`. This function accepts incoming connections. Then for each connection, it starts a thread
 to read messages from the socket through the function `read_message_from_socket`. This function reads incoming messages and appends them to the network queue of the machine.
 5) We ensure that all servers are running before connecting to them for writes. 
 6) After setting up all the read and write sockets (total of 6 sockets), we get a random clock value (unless specified), initialize the logical clock to zero, and then make the
 machine start running the actions specified in the spec through `do_thread_actions`.
 7) Inside `do_thread_actions` we execute actions according to the assignment specifications.

########################

Unit testing:

Most of the functions in our code require opening sockets between multiple processes. We don't do any unit testing with these functions.

We do unit tests with the log writing functions that each of the processes use.
We test init_log_file() and write_to_log()

For init_log_file(), we test normal behavior of opening a log file, whether the function correctly overwrites a file rather than appending, and passing in different parameter types.

For write_to_log(), we test normal behavior of adding one line to an empty file, appending lines to a written file, initializing the file if it doesn't exist, and passing in different parameter types.

########################

Experiments:

We run the following 5 experiments on this three-machine model, with 5 runs each:

# Experiment 0: Run with default settings
# Experiment 1: All clock rates are exactly the same
# Experiment 2: 0, 1 are slow clock rate, 2 is very very fast
# Experiment 3: 0 is slow, 1 and 2 are fast
# Experiment 4: Default clock rates, but super likely to send messages (act_range down to 4)

These experiments cover a wide range of cases where the machines run at different rates and also
are more or less likely to send messages to each other.

Execute the experiments using 
$ ./experiments.sh

########################

Findings:

# Experiment 0: Run with default settings
- The process with the fastest clock rate will send the most messages and generally dictate the logical clock values of the other, slower processes. The final clock values for all processes is generally at or slightly less than the fastest clock process.
- Processes with slower clock rates will spend more actions reading messages rather than rolling their action dices.
- Processes with slower clock rates will send out far fewer messages since they have to read more messages.
- Processes with slower clock rates will update their logical clock value far more often, to match the clock values they read from the messages.

# Experiment 1: All clock rates are exactly the same
- All processses are almost lock-stepped with their clock values. Sometimes one will get 1 or 2 ahead of another, likely due to process scheduling, but no greater than 2 apart.
- When a process receives a message, it will update at most 1 clock tick greater than what it had.
- Message queues generally will not grow larger than 1, so no process gets hung up consuming messages rather than taking actions.
- All processes generally send and consume the same number of messages.

# Experiment 2: 0, 1 are slow clock rate, 2 is very very fast
- Process 2, the fastest, doesn't receive many messages.
- Process 2 sends many messagse.
- Process 2's clock value dictates the clock values of the other, slower processes.
- Process 0, the slowest, can build up a giant message queue. Since it is consuming messages slower than it is receiving them, its clock value falls further behind as time passes. Needless to say, it doesn't send out any messages or take any actions besides reading messages. We notice this infinite message queue growth when Process 0 runs 1 tick per second and Process 2 runs 6 ticks per second. This, in theory, makes sense, since the expected number of messages per second that Process 2 sends to Process 0 is 6*2/10 = 1.2 while Process 0 can read at most 1 message per second.
- Process 1, the second slowest, suffers from the same problems as Process 0, but we never saw it build the infinite message queue.

# Experiment 3: 0 is slow, 1 and 2 are fast
- Similar to the previous experiment, we find that Process 0 builds the infinite message queue. Process 0 begins to catch up to the reading when the clock rates for the three processes are (4, 9, 11). Once the clock rates hit (5, 10, 12), Process 0 catches up and is generally able to do internal event actions and even send its own messages.
- There is certainly some math about the expected number of messages from each process and how many process 0 can read, but this is an engineering class so I don't do this math here and leave it as an exercise for the reader.
- Process 1, which is slower than Process 2 but still far faster than Process 0, generally does more recieves than Process 2. It falls behind slightly in clock value, but not far.


# Experiment 4: Default clock rates, but super likely to send messages (act_range down to 4)
- Here, no internal events are possible. If there is an event then it will be a send.
- In all cases, the slowest process builds the infinite message queue.
- If there are two processes which are slowest, both will build infinite message queues. In this case, the single faster process will never receive any messages and just populate the other two process' queues with sends.

Overall:
- The faster the process, relative to the other processes, the less time it will spend on receiving messages and the more internal events and message sends it will do.
- The fastest process will dictate the clock value of the other two processes. It will not jump when it receives messages, but the slower processes will jump their clock values as they receive the fastest process' messages.
- For the default action range of 10, if the slowest process is 1/6th of the clock rate as the sum of the two faster processes, then it will build an infinite queue and fall behind the other processes in clock value.
- When the action range is squeezed, the infinite message buildup is more problematic, because the fastest process is more likely to execute sends and fill the message queues of the other processes.
